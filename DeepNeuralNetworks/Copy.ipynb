{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let us load the required data into individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/suman/DspData/data/churn_train_X.csv') \n",
    "y_train = pd.read_csv('C:/Users/suman/DspData/data/churn_train_y.csv') \n",
    "X_test = pd.read_csv('C:/Users/suman/DspData/data/churn_test_X.csv') \n",
    "y_test = pd.read_csv('C:/Users/suman/DspData/data/churn_test_y.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a data frame called performance and put all the needed metrics in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 8 is smaller than n_iter=500. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "The best recall score is 0.5669050216135417\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.         0.56690502 0.         0.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.         0.56917868 0.         0.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['None','l1','l2','elasticnet'],\n",
    "    'solver':['saga','liblinear']\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.5695996444875369\n",
      "... with parameters: {'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "penalty = rand_search.best_params_['penalty']\n",
    "solver = rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {  \n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallLogistic = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.57393</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision   Recall        F1\n",
       "0  Logistic Regression  0.903587   0.799458  0.57393  0.668177"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression\",\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "print(TP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Linear) - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset (only training data)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_up, y_up = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "     'C':[1,100,1000],\n",
    "    'gamma':[0,10,100],\n",
    "'kernel':['linear']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=3,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_up, y_up)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (RBF) - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.001, 0.10, 0.0001,0.00001],   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['rbf']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=3,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_up, y_up)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best SVM recall I observed : 77%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: I tried to run SVM model for 7 hours and didnt got any results. May be I'm using too many training examples for SVM implementation.Overall, SVMs can be slow to train because of their complexity, particularly when working with large datasets or high-dimensional data. However, the trade-off is that SVMs are often very accurate and effective for a wide range of classification problems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees - Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.7861754130812427\n",
      "... with parameters: {'min_samples_split': 19, 'min_samples_leaf': 15, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 66, 'max_depth': 11, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,100),  \n",
    "    'min_samples_leaf': np.arange(1,75),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 80), \n",
    "    'max_depth': np.arange(1,40), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE - GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.7969862238920535\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 65, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 13, 'min_samples_split': 17}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.573930</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.826004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.903587   0.799458  0.573930  0.668177\n",
       "0        Decision Tree  0.940112   0.812030  0.840467  0.826004"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, for this assignment we have to use Logistic Regression, SVM, and Decision tree. But the dataset is best suited for Random Forest Algorithm (From the dataset website) and  It's important that we don't predict churning as non-churning customers. That's why the model needs to be evaluated on the \"Recall\"- metric (goal > 77%). And also I tried to Upsample the imbalanced dataset using SMOTE Technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset (only training data)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_up, y_up = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_7920\\1298015926.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_up, y_up)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_up, y_up)\n",
    "\n",
    "rfpred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.573930</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.826004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.945048</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.896887</td>\n",
       "      <td>0.846648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy  Precision    Recall        F1\n",
       "0       Logistic Regression  0.903587   0.799458  0.573930  0.668177\n",
       "0             Decision Tree  0.940112   0.812030  0.840467  0.826004\n",
       "0  Random Forest Classifier  0.945048   0.801739  0.896887  0.846648"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = (confusion_matrix(y_test, rfpred))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest Classifier\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "print(TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      2525\n",
      "           1       0.00      0.00      0.00       514\n",
      "\n",
      "    accuracy                           0.83      3039\n",
      "   macro avg       0.42      0.50      0.45      3039\n",
      "weighted avg       0.69      0.83      0.75      3039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 30), 'alpha': 1, 'activation': 'logistic'}\n",
      "Wall time: 8min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      2525\n",
      "           1       0.00      0.00      0.00       514\n",
      "\n",
      "    accuracy                           0.83      3039\n",
      "   macro avg       0.42      0.50      0.45      3039\n",
      "weighted avg       0.69      0.83      0.75      3039\n",
      "\n",
      "Wall time: 41.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (30,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      2525\n",
      "           1       0.00      0.00      0.00       514\n",
      "\n",
      "    accuracy                           0.83      3039\n",
      "   macro avg       0.42      0.50      0.45      3039\n",
      "weighted avg       0.69      0.83      0.75      3039\n",
      "\n",
      "Wall time: 16.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks, particularly deep neural networks, have shown to be effective in various machine learning tasks, including classification, regression, and pattern recognition. When it comes to recall, which is a measure of a model's ability to correctly identify positive cases out of all actual positive cases, neural networks have certain advantages that can make them perform better than other models.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While comparing all other models and neural networks we got better recall value for neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, while other models like logistic regression or decision trees can also achieve good recall, neural networks have certain advantages that can make them perform better in certain cases. However, it's important to note that the performance of a neural network depends on several factors, including the choice of architecture, training algorithm, and hyperparameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion :The goal of this project is to provide an analysis which shows the difference between a non-churning and churning customer. Using the existing data managed to train a model with upsampled data which reaches a recall score of 89%.This will provide us insight into which customers are eager to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 9.47003620\n",
      "Validation score: 0.843441\n",
      "Iteration 2, loss = 10.10287244\n",
      "Validation score: 0.843441\n",
      "Iteration 3, loss = 8.73548114\n",
      "Validation score: 0.843441\n",
      "Iteration 4, loss = 9.53782919\n",
      "Validation score: 0.843441\n",
      "Iteration 5, loss = 9.52652596\n",
      "Validation score: 0.843441\n",
      "Iteration 6, loss = 10.28367246\n",
      "Validation score: 0.843441\n",
      "Iteration 7, loss = 8.79197575\n",
      "Validation score: 0.843441\n",
      "Validation score did not improve more than tol=0.000010 for 5 consecutive epochs. Stopping.\n",
      "CPU times: total: 1.81 s\n",
      "Wall time: 656 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(60,50,40), \n",
    "    activation = 'relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001, # Strength of the L2 regularization term\n",
    "    batch_size='auto',\n",
    "    learning_rate = 'constant',\n",
    "    learning_rate_init = 0.001,\n",
    "    max_iter=200,\n",
    "    tol=0.00001, \n",
    "    early_stopping = True,\n",
    "    n_iter_no_change = 5,\n",
    "    verbose=True\n",
    "    \n",
    ")\n",
    "_ = model1.fit(X_train, y_train)\n",
    "\n",
    "# Currently (version 1.2.2), MLPClassifier supports only the Cross-Entropy loss function.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.47003620128886,\n",
       " 10.102872437657616,\n",
       " 8.735481140413357,\n",
       " 9.537829193647294,\n",
       " 9.526525960117464,\n",
       " 10.283672458567988,\n",
       " 8.791975746067356]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 16.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.831     1.000     0.908      2525\n",
      "           1      0.000     0.000     0.000       514\n",
      "\n",
      "    accuracy                          0.831      3039\n",
      "   macro avg      0.415     0.500     0.454      3039\n",
      "weighted avg      0.690     0.831     0.754      3039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.16 s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [ (64,), (128,),(128,64), (64,128), (64,128,196), (196,128,64)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .0001, .0005, .001, .005],\n",
    "    'batch_size': [25, 50, 100],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.0005, 0.001, 0.005, 0.01],\n",
    "    'max_iter': [5000],\n",
    "    'tol': [0.000005, 0.00001, 0.00005],\n",
    "    'early_stopping':[True],\n",
    "    'n_iter_no_change':[5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = MLPClassifier(), # a blank slate... RandomizedSearchCV will send parameters.\n",
    "    param_distributions=param_distributions, \n",
    "    cv=3, \n",
    "    n_iter=300,\n",
    "    scoring='accuracy', # note that we could also choose any other scoring metric that is appropriate for a multi-class problem - such as f1_macro, f1_micro, f1_weighted, etc.\n",
    "    verbose=1, \n",
    "    n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "_ = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 1e-05, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 5000, 'learning_rate_init': 0.005, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (128,), 'early_stopping': True, 'batch_size': 100, 'alpha': 0.0001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "model2 = random_search.best_estimator_\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8309    1.0000    0.9076      2525\n",
      "           1     0.0000    0.0000    0.0000       514\n",
      "\n",
      "    accuracy                         0.8309      3039\n",
      "   macro avg     0.4154    0.5000    0.4538      3039\n",
      "weighted avg     0.6903    0.8309    0.7541      3039\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 35.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 64,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 64,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['sparse_categorical_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 28441911700611923968.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8928\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6546\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4550\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2924\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.1618\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0593\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9786\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9152\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8650\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37898388998648233984.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8926\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6549\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4550\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2919\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.1614\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0588\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9784\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9151\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8649\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23054476248323457024.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8925\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6547\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4553\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2922\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.1622\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.0594\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9789\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9155\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8652\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 97904256.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 387482.9688\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 574344.9375\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 488403.3438\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 556020.8125\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 232786.7656\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 475823.2812\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 510487.2500\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 755711.9375\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 694490.9375\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10200326.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 429434.0625\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 358743.8438\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 684605.9375\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 894385.5625\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 968837.6875\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 335998.7500\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 524312.8125\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1439456.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 933345.2500\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24503826.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 825116.0625\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 954821.5000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 823663.5625\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 712046.3125\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 785044.6250\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 681201.8125\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 500394.4688\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 685795.3750\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 510020.3125\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1490358599514324992.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.0030\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.7739\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6841\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6355\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6029\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5786\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5595\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5442\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5318\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1897551735744888832.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.0042\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.7740\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6841\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6356\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6029\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5786\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5595\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5442\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5318\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1625293002937204736.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.0017\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.7732\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6841\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6354\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6027\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5784\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5593\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5440\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5316\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1402224546676736.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2981\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2920\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2890\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2829\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2799\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2769\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2739\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3778147707256832.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2981\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2890\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2829\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2799\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2769\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2739\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2234521697124352.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2981\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2890\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2830\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2799\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2769\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2739\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 123833272.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 68893336.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 52356308.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 44315704.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 37509996.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 31079408.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 24320206.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 18501548.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 12955519.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 10398081.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 134543600.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 52112728.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 21249904.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 16380451.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 15133476.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 14680359.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13864098.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 13994225.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13568677.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13359825.0000\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 63845004.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 23813018.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13534952.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 10706587.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9514560.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 9132203.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 8504248.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 8587606.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 8214517.5000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 8133784.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 26155277090816000.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.0866\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.9516\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.8253\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.7081\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.6002\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.5016\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.4122\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.3317\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.2594\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 23981501800513536.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.0866\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.9516\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.8253\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.7081\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.6002\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.5016\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.4123\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.3318\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.2595\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 23128328021999616.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.0865\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.9515\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.8253\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.7082\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.6003\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.5017\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.4124\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.3318\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.2596\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 337757727891300286464.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1815\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1211\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.0613\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0029\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9453\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8883\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8308\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.7750\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.7196\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 6429790876846717403136.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9196\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9118\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8954\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9134\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9013\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9230\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9010\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9131\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8952\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 3498941407571289833472.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2320\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.1781\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1249\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0727\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0218\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9721\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9235\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8762\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8295\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2941384461910016.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2981\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2890\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2830\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2799\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2769\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2739\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2671870163812352.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2981\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2890\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2860\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2829\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2799\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2769\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2739\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3112304296067072.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2981\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2890\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2830\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2799\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2769\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2739\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6636748.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 394827.9062\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 14538.3330\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2432.8201\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8433.2393\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 590.0364\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4358\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4357\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4360\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4367\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4273049.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 286547.5938\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 75082.6250\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 64384.0820\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2614.5959\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 493.7281\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 47.9218\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.9242\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5957\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4782\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 3990208.2500\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 498081.7500\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 27069.8086\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10141.3037\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 3198.2778\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 851.4575\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 505.5600\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 275.9931\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 234.3712\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 124.1590\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30571454606122503907573760.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9281\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6828\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4774\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3104\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.1761\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0705\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9874\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9222\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8706\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 27007405300501265713725440.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9219\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.6732\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4626\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2872\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1443\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0293\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9381\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8652\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8083\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 9572707252750650441728000.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9314\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6873\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4815\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3124\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1768\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0691\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9843\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9169\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8634\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 270066718938759168.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2584\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2284\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1988\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1696\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1406\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1120\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0836\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0556\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0280\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 227561523554287616.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2584\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2285\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1988\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1695\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1405\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.1119\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0835\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0556\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0279\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 164373638278021120.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2584\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2285\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1989\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1696\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1407\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1120\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0838\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0558\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0282\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 5324318.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2301733.2500\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2202678.5000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 873295.9375\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 897607.7500\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 701350.0625\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 514305.0312\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 257888.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 194589.0625\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 73720.4453\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4078982.2500\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2537714.7500\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 677179.0625\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 494524.2188\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 332666.6562\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 150079.8438\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 69262.1094\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 31884.0488\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7303.3159\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1651.9529\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 7503393.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2547814.2500\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1452421.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 761659.3750\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 423494.2500\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 189027.2969\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 144188.4844\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 52208.3906\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6513.3286\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1197.7000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1058931166150656.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2852\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2702\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2603\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2554\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2629765257232384.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2852\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2703\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2653\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2603\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2554\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1494062490189824.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2852\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2702\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2603\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2554\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 10352010.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 5088027.5000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1336941.7500\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4134035.2500\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2354744.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1738369.7500\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 918138.5625\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1258818.6250\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 999927.2500\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 590651.8125\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 11561544.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2625468.7500\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 5559114.5000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2390767.7500\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2406974.5000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3293029.7500\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3371183.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2381835.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1480848.2500\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1517958.3750\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 20656260.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3734086.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2222529.5000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3243967.7500\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1834273.8750\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1304305.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1266288.8750\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1174369.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1237178.6250\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 506023.1562\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 53108988876836306944.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8948\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6564\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4566\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2938\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1630\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0604\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9796\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9162\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8659\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21028977917867065344.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8926\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6549\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4550\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2919\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1614\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0588\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9784\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9151\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8649\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 25080939949989036032.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8926\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6549\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4554\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2923\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1622\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0594\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9790\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9155\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8652\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16692543.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3125391.5000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1256758.5000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1166960.6250\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 425194.0312\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 99337.8047\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 61447.0234\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26130.2949\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 38809.6289\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.4643\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 15438803.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3959859.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1109629.1250\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1087113.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 568975.3125\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 907383.0625\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 362787.3125\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 184039.2656\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 110784.3750\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27534.4766\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15391589.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2902500.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1764209.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 291304.3438\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 733279.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 359929.3750\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 55983.5664\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9631.0332\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9819.4688\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7985.0054\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15317670.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2848165.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6226173.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4178552.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3321302.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4028519.2500\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2487068.2500\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2933539.2500\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2418066.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4007064.7500\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12019962.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6589471.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4364569.5000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4406289.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2958027.2500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1240200.6250\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3146409.2500\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2509391.7500\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1229015.2500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 830396.0000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12825345.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2905705.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3587593.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6184672.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3860724.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3381624.5000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3573491.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2933981.5000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2338089.7500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2234934.5000\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 7894919.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2422179.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1270970.3750\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 744318.8125\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 335707.1562\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 178146.5469\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 43874.8359\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 12631.8965\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 51812.2422\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 218796.7031\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 5868405.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1862322.6250\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 857072.7500\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 609557.4375\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 290892.5312\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 90912.6016\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 294264.1250\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 59309.5586\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 4751.2798\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 424.7148\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6331166.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 3840879.7500\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1522176.2500\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1068173.3750\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 420683.0625\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 216058.6875\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 89071.0547\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 23412.6035\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10408.8477\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1982.7799\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 5994561583890563072.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7890\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7977\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7931\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7992\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8094\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8031\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8061\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8017\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7891\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 1390089323814060032.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2953\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2896\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2837\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2779\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2722\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2667\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2609\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2554\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2498\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 19987076301340016640.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2233\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.2249\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2279\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2097\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2124\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2059\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2091\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2016\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2123\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 50342088.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 755718.5000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 925684.8125\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 765999.4375\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 806465.0625\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 740788.5000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 564380.2500\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 689888.4375\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 553049.9375\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 535113.3125\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 36540012.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 859975.0625\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 218794.6250\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 490962.9375\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 536881.5625\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 360983.9375\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 601852.1250\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 437615.9062\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 629043.5000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 575666.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 6521196.5000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 751656.8750\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1175870.2500\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 809064.3750\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 583922.1250\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 372573.1250\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 380248.3438\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 668359.3125\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 859329.2500\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1074273.1250\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 209463826972672.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2063\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1773\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 211331886088192.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2063\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 358894748565504.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2064\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.1774\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8735944494823111470874624.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7948\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4561\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.1607\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9387\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7965\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7139\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6631\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6286\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6024\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28160651928972411820572672.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8154\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4915\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2086\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9933\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8529\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7690\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7165\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6797\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6511\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12458171172111895249289216.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7858\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4480\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1497\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9244\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7826\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7002\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6508\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6175\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5925\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 11982783383735369728.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.6633\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3525\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1341\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9864\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8867\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8183\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7693\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7330\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7050\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 7513740307314245632.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.6647\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3535\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1347\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9868\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8870\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8184\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7694\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7331\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7050\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 3752195305093726208.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.6625\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3520\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1341\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9866\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8872\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8187\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7697\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7334\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7054\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16743061608072870887424.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2238\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.1815\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1397\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0984\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0572\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0164\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9758\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9357\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8961\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3185087519864676941824.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2479\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2074\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1676\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1283\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0910\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0551\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0199\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9852\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9507\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34717646045049086017536.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2782\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2412\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2049\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1691\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1338\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0989\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0645\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0304\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9967\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 42276092.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 12170645.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9796836.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9657038.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 9306696.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8805880.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 8133284.5000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7799138.5000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6740669.5000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6324936.5000\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 86546472.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 17905142.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 8062319.5000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6848660.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6396019.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6380347.5000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 5391243.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 5469853.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5309523.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4864161.0000\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 30781844.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 12021248.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 9126660.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 8963242.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 7901026.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7522338.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 7105220.5000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6494264.5000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6296054.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 5670004.0000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 5932074139060797440.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.0037\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.7745\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6846\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6359\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6032\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5788\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5597\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5444\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5320\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1770189668902502400.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.0026\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.7735\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6840\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6355\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6029\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5786\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5595\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5441\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5318\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2715206031641673728.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.0017\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.7732\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6841\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6354\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6027\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5784\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5593\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5440\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5316\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 104303048855126016.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2293\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1807\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1330\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.0862\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.0402\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9953\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9512\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9082\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.8661\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 125668930604761088.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2293\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1807\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1330\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.0862\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.0402\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9952\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9512\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9081\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8660\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 124322784774979584.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2294\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1808\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1331\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.0863\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.0404\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9954\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9514\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9083\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.8662\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4314520461032554496.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2922\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2724\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2528\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2336\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2146\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1958\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.1770\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1585\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1400\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2110961032821211136.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5424\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5410\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5406\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5402\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5398\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5394\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5390\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5387\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5383\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2286371757797408768.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.3066\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2857\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2661\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2483\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2309\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2136\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1966\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1806\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1647\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 210359080022179840.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2585\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2285\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1989\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1697\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1406\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1120\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0837\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0557\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0280\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 333553001362882560.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2585\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2285\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1989\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1696\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1406\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1119\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0836\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0556\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0280\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 322430891492114432.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2584\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2285\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1989\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1696\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1407\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1120\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0838\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0558\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0282\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 272422326501376.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2063\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.1773\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 113060182228992.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2063\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 280266698391552.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2064\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 11071376.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1009329.5000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 376091.5625\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 75082.0859\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 51207.4883\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 53127.4453\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8970.1143\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2251.5537\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2640.3423\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2951.2329\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 7488972.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 559166.8750\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 184867.8125\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 69171.1719\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7965.1064\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 6757.1235\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6600.4653\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5968.0923\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4220.6943\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1904.7488\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 8600561.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 846230.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 383589.0938\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 150231.1875\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 68149.0469\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14647.0078\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8364.5488\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8733.8809\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9754.6572\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6393.2075\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3102093.5000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2387626.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1501151.1250\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2843288.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2496606.5000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2074513.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2435019.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2488910.2500\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1220084.7500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1588421.3750\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11134458.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2496126.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1267048.6250\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1684528.8750\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2202229.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2104472.2500\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2405822.2500\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1776673.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1012237.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1110540.8750\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 9085060.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1527890.6250\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 766138.6250\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1914318.6250\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1198333.3750\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1051257.8750\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1096211.6250\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 974165.9375\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 612303.8750\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 550443.2500\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1704606753095680.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2852\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2702\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2603\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2554\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1216863019204608.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2852\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2703\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2603\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2554\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1644477747822592.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2852\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2752\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2703\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2603\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2554\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 22096696.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 192335.3750\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 283043.9062\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 183751.8906\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 245662.3125\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 265373.6562\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 310888.8438\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 232607.2812\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 253309.5938\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 258799.2656\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 11550503.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 144051.5000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 189114.4375\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 115343.2266\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 213253.9062\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 205442.5312\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 215465.6875\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 184724.8906\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 251368.6719\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 202854.7812\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 581737.5625\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 291826.5938\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 373229.9375\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 359842.4375\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 376398.3750\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 461800.9375\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 369355.5312\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 311670.0625\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 295284.1875\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 303321.8438\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 262791376.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 192973696.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 123404360.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 63685116.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27438036.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19294916.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16477574.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14934025.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13682719.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14116306.0000\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 149609696.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 90027232.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42917184.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23656802.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 17219630.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13189092.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11783238.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10842252.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9835200.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8912068.0000\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 284576832.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 231284608.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 183828640.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 137744976.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 91480224.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 48055692.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22648884.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16290881.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14409464.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13609271.0000\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 68026928.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10260763.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 8918031.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 9114204.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 8132114.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7692231.5000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 7286290.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6997860.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6702551.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6228762.5000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 55331724.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 19875548.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 13128095.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 12351039.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 11118044.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10949175.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 10347934.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 9892321.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 9274609.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 9033910.0000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 37767080.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10978889.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 8457131.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 8026372.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7436616.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7309824.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6819385.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 6684989.5000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 5904202.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 5611716.0000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 15001775.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 61182.9375\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 54844.4258\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 59637.3477\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 61032.4727\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 82725.5312\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 79704.8906\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 75146.1562\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 70456.3125\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 66569.3750\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 88502784.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 91009.6562\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 50107.9023\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 41320.7617\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 63469.5938\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 62444.7852\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 63410.6562\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 61400.7070\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 38633.0625\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 64509.9531\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 29820406.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 52020.1523\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 94173.3672\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 89873.9844\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 91389.8203\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 102080.3281\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 93115.4219\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 102041.7969\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 69253.1094\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 91001.9453\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 164779557650432.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2063\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1773\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 223915133632512.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2504\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2063\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 961151135383552.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2802\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2653\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2505\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 2.2210\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.2064\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.1630\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1682247155500187648.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5575\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5380\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5349\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5222\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5157\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5207\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5142\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5096\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5153\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 159328605295069687118299136.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5204\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5149\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5207\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5168\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5234\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5319\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5212\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5141\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5268\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4252274633882992640.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.7201\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7028\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.7188\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7171\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.7141\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.7109\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7132\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.7164\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7051\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 12117111818812391424.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.6635\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3526\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1342\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9865\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8868\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8183\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7694\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7331\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7050\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1785353171200114688.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.6651\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3538\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1349\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9869\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8871\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8184\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7694\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7331\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7050\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 27506046985467592704.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.6644\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3534\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1350\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9872\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8876\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8190\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7699\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7336\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7055\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 146067840.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 89829144.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34292952.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6533619.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1988786.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 192653.6094\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 78794.9531\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 61530.3125\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 75990.5625\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 72494.7109\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20798316.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11778316.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2933646.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 96255.1484\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 99018.6016\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 130577.1328\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 75102.0391\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 94294.0078\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 104014.7812\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 66402.2969\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 34154864.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2151411.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 108681.5234\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 59414.9141\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 49004.5469\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45984.9375\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43293.7969\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 62997.9805\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23028.4375\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 65622.8750\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 9042220.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2092450.5000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 704443.3125\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 67548.9844\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 28523.8281\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 6365.0732\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1235.8833\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 726.4443\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2299.9636\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2296.1799\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 11559812.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2311275.7500\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 638332.7500\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 722943.0625\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 158951.8594\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 177327.3594\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 28975.4375\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 43431.1328\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4996.1362\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 980.2672\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 14114042.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1150658.3750\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 778461.4375\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 872077.3125\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 172459.0938\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 76913.4766\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 20844.1074\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2954.0076\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2449.0276\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 267.4203\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4248081710062143275008.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.0589\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.9067\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.7606\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.6206\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.4871\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.3610\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.2437\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.1369\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.0422\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1324915663225986482176.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 2.0464\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.8806\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.7218\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.5705\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.4268\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.2927\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.1708\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.0636\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.9727\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1848577198660536762368.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.9828\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.8006\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.6234\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.4531\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2947\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 1.1538\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.0355\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.9410\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.8682\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 10562034374993357307904.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6207\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6121\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.5929\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5896\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6009\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5948\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5990\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.5860\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.5959\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 13147468730373559549952.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2574\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2252\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.1933\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1617\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.1303\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0992\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0684\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0381\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0079\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4316077901661113155584.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9016\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9049\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9185\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9087\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9238\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9074\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9032\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.8921\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9012\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 161098976.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 95634032.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 40362072.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 22364362.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 17220646.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 15104446.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 14457568.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 13162789.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 12440810.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 12284793.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 43893004.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 19306038.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 15186470.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13223931.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 12013424.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 11430731.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 11276461.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 10372849.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 10028869.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 10287030.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 204259376.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 134233760.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 71584856.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 28851620.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 17021886.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13527254.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 13036810.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 12246978.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 11666783.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 11659185.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2344940.7500\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 868353.4375\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 607865.6875\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 309385.9062\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 632593.6875\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 677276.5625\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 688592.4375\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 716780.1250\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 912454.7500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 953135.1875\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 19176840.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 694033.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 566656.8125\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 538257.4375\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 416009.6562\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 650456.7500\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 459621.4375\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 652569.3750\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 332451.3125\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 392830.6875\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6104131.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 549560.8125\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 898575.9375\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 733529.3750\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 300628.6562\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 652286.8125\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 457662.6250\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 829907.5625\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 717849.8125\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1113793.2500\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 9984919.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 7790005.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7458049.5000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6677000.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 6113470.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 5819213.5000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 5171972.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4772522.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4375235.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4054307.0000\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 140188112.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 18433792.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 12527777.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 11804503.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 11586083.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10745842.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 10492501.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 10079732.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9092941.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 9023302.0000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 101746680.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 18468246.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 13292729.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 11528290.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 11207070.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 10641813.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 9495471.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 9443625.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 8422901.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 7691002.0000\n",
      "119/119 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26623156740549509120.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8930\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6548\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4551\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2925\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.1619\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0594\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9786\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9152\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8650\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35848675024101703680.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8927\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6549\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4551\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2920\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.1615\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0588\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9784\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9151\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8649\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16183824898932604928.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8938\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6558\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4562\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2930\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1627\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0598\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9793\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9158\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8654\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 51308176.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 29776330.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 21737072.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13882735.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 6061375.5000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 418484.1250\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 73357.1719\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 122644.3438\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 110538.9844\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 67715.5781\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 174341552.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 87276720.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 13317420.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 113523.7344\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 18181.5527\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 36055.1289\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 50959.4180\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 42906.8320\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 44351.0156\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 62057.0430\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 81665696.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 15745055.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 126134.4688\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 34198.8828\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 48257.3008\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 40899.0898\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 44963.1836\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 48651.9258\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 65279.3164\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 69696.8281\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 33484392.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12643968.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11033705.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10132146.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9240074.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7940244.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6781803.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5894276.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4911283.5000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4205361.0000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47895368.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10876830.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10851873.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9526018.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8527934.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7467894.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6327525.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5755069.5000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5340399.5000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4475817.0000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62806832.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10429708.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10278850.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8035768.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7633247.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6540549.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5772250.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4957261.5000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4343653.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3666015.2500\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 10015785668946427904.0000\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 1.7183\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 1.4207\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 1.2012\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 1.0457\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.9369\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.8602\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.8047\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.7634\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.7316\n",
      "CPU times: total: 1h 4min\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='accuracy',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=50, \n",
    "    cv=3)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)\n",
    "\n",
    "# You can create 'call back' functions. These are functions that will be called at the \n",
    "# end of each epoch. There are a number of builtin functions created for this purpose, \n",
    "# one of which is EarlyStopping -- that, based on the parameters you give, will stop\n",
    "# the training process. This is useful when the algorithm is not making any significant\n",
    "# gains through further training. \n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "#callback = [earlystop]\n",
    "#_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.01,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (70,),\n",
       " 'model__dropout': 0,\n",
       " 'loss': 'sparse_categorical_crossentropy',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 100}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8309    1.0000    0.9076      2525\n",
      "           1     0.0000    0.0000    0.0000       514\n",
      "\n",
      "    accuracy                         0.8309      3039\n",
      "   macro avg     0.4154    0.5000    0.4538      3039\n",
      "weighted avg     0.6903    0.8309    0.7541      3039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
