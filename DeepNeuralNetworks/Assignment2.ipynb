{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score ,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Now, let us load the required data into individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(\"C:/Users/suman/OneDrive/Desktop/Surya/online_price_train_X.csv\")\n",
    "X_test = pd.read_csv(\"C:/Users/suman/OneDrive/Desktop/Surya/online_price_test_X.csv\")\n",
    "y_train = pd.read_csv(\"C:/Users/suman/OneDrive/Desktop/Surya/online_price_train_y.csv\")\n",
    "y_test = pd.read_csv(\"C:/Users/suman/OneDrive/Desktop/Surya/online_price_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a data frame called performance and put all the needed metrics in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.1 Logistic Regression with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 8 is smaller than n_iter=500. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "The best recall score is 0.8657534246575344\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'none' (deprecated), 'l2'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'none' (deprecated), 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l2', 'elasticnet', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'none' (deprecated), 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'none' (deprecated), 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.81643836 0.86575342 0.81643836 0.86575342\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.81883562 0.87157534 0.81986301 0.87123288\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['None','l1','l2','elasticnet'],\n",
    "    'solver':['saga','liblinear']\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "The best recall score is 0.8657534246575344\n",
      "... with parameters: {'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "penalty = rand_search.best_params_['penalty']\n",
    "solver = rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {  \n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallLogistic = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.902208</td>\n",
       "      <td>0.913738</td>\n",
       "      <td>0.907937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.905537   0.902208  0.913738  0.907937"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression\",\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 SVM (Linear) - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 38 is smaller than n_iter=50. Running 38 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8684931506849315\n",
      "... with parameters: {'kernel': 'linear', 'gamma': 'scale', 'C': 3}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,20),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['linear']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=50,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 SVM (Linear) - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The best recall score is 0.8671232876712329\n",
      "... with parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 180, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of SVC must be a float in the range (0.0, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.86712329 0.86712329 0.86712329 0.86712329 0.86712329]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.86849315 0.86849315 0.86849315 0.86849315 0.86849315]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-3,C+3),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallSVM_linear = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.902208</td>\n",
       "      <td>0.913738</td>\n",
       "      <td>0.907937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-Linear</td>\n",
       "      <td>0.920195</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.894569</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.905537   0.902208  0.913738  0.907937\n",
       "0           SVM-Linear  0.920195   0.945946  0.894569  0.919540"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM-Linear\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 SVM (RBF) - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 38 is smaller than n_iter=50. Running 38 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8931506849315068\n",
      "... with parameters: {'kernel': 'rbf', 'gamma': 'auto', 'C': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,20),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['rbf']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=50,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2 SVM (RBF) - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The best recall score is 0.9095890410958904\n",
      "... with parameters: {'C': 20, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-3,C+3),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallSVM_rbf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.902208</td>\n",
       "      <td>0.913738</td>\n",
       "      <td>0.907937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-Linear</td>\n",
       "      <td>0.920195</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.894569</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-RBF</td>\n",
       "      <td>0.903909</td>\n",
       "      <td>0.891975</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.907378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.905537   0.902208  0.913738  0.907937\n",
       "0           SVM-Linear  0.920195   0.945946  0.894569  0.919540\n",
       "0              SVM-RBF  0.903909   0.891975  0.923323  0.907378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM-RBF\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.1 SVM (Poly) - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8671232876712329\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 0.001, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'gamma':[1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'C':[0.001, 0.10, 0.0001,0.00001],\n",
    "    'kernel':['poly']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=10,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.2 SVM (Poly) - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 180, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of SVC must be a float in the range (0.0, inf). Got -2.9 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 180, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of SVC must be a float in the range (0.0, inf). Got -1.9 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 180, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of SVC must be a float in the range (0.0, inf). Got -0.8999999999999999 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.87123288 0.86712329 0.86986301]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 0.87328767 0.87465753 0.87534247]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8712328767123287\n",
      "... with parameters: {'C': 0.10000000000000009, 'gamma': 0.001, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-3,C+3),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallSVM_poly = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.902208</td>\n",
       "      <td>0.913738</td>\n",
       "      <td>0.907937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-Linear</td>\n",
       "      <td>0.920195</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.894569</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-RBF</td>\n",
       "      <td>0.903909</td>\n",
       "      <td>0.891975</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.907378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-Poly</td>\n",
       "      <td>0.915309</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.900958</td>\n",
       "      <td>0.915584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.905537   0.902208  0.913738  0.907937\n",
       "0           SVM-Linear  0.920195   0.945946  0.894569  0.919540\n",
       "0              SVM-RBF  0.903909   0.891975  0.923323  0.907378\n",
       "0             SVM-Poly  0.915309   0.930693  0.900958  0.915584"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM-Poly\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.1 Decision Trees - Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.9150684931506848\n",
      "... with parameters: {'min_samples_split': 23, 'min_samples_leaf': 11, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 68, 'max_depth': 25, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,100),  \n",
    "    'min_samples_leaf': np.arange(1,75),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 80), \n",
    "    'max_depth': np.arange(1,40), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2 DECISION TREE - GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.9232876712328768\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 23, 'max_leaf_nodes': 66, 'min_impurity_decrease': 5e-05, 'min_samples_leaf': 9, 'min_samples_split': 22}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallDTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.56 s\n",
      "Wall time: 512 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 4.75 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       301\n",
      "           1       1.00      0.65      0.78       313\n",
      "\n",
      "    accuracy                           0.82       614\n",
      "   macro avg       0.86      0.82      0.81       614\n",
      "weighted avg       0.87      0.82      0.81       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6.1 Neural Networks With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 30), 'alpha': 1, 'activation': 'tanh'}\n",
      "CPU times: total: 3.66 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       301\n",
      "           1       0.89      0.92      0.90       313\n",
      "\n",
      "    accuracy                           0.90       614\n",
      "   macro avg       0.90      0.90      0.90       614\n",
      "weighted avg       0.90      0.90      0.90       614\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 20.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6.2 Neural Networks With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (70,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 3.38 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       301\n",
      "           1       1.00      0.65      0.79       313\n",
      "\n",
      "    accuracy                           0.82       614\n",
      "   macro avg       0.87      0.83      0.82       614\n",
      "weighted avg       0.87      0.82      0.82       614\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 21.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.902208</td>\n",
       "      <td>0.913738</td>\n",
       "      <td>0.907937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-Linear</td>\n",
       "      <td>0.920195</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.894569</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-RBF</td>\n",
       "      <td>0.903909</td>\n",
       "      <td>0.891975</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.907378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM-Poly</td>\n",
       "      <td>0.915309</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.900958</td>\n",
       "      <td>0.915584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.926710</td>\n",
       "      <td>0.911043</td>\n",
       "      <td>0.948882</td>\n",
       "      <td>0.929577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.905537   0.902208  0.913738  0.907937\n",
       "0           SVM-Linear  0.920195   0.945946  0.894569  0.919540\n",
       "0              SVM-RBF  0.903909   0.891975  0.923323  0.907378\n",
       "0             SVM-Poly  0.915309   0.930693  0.900958  0.915584\n",
       "0        Decision Tree  0.926710   0.911043  0.948882  0.929577"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7.1 MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 11.35123364\n",
      "Validation score: 0.493151\n",
      "Iteration 2, loss = 7.49112559\n",
      "Validation score: 0.500000\n",
      "Iteration 3, loss = 8.82611173\n",
      "Validation score: 0.500000\n",
      "Iteration 4, loss = 6.14701907\n",
      "Validation score: 0.500000\n",
      "Iteration 5, loss = 5.33649017\n",
      "Validation score: 0.500000\n",
      "Iteration 6, loss = 4.26366312\n",
      "Validation score: 0.500000\n",
      "Iteration 7, loss = 3.28785917\n",
      "Validation score: 0.589041\n",
      "Iteration 8, loss = 1.81747140\n",
      "Validation score: 0.513699\n",
      "Iteration 9, loss = 1.63405129\n",
      "Validation score: 0.582192\n",
      "Iteration 10, loss = 0.99550739\n",
      "Validation score: 0.541096\n",
      "Iteration 11, loss = 0.84324448\n",
      "Validation score: 0.609589\n",
      "Iteration 12, loss = 0.68974206\n",
      "Validation score: 0.684932\n",
      "Iteration 13, loss = 0.62973180\n",
      "Validation score: 0.698630\n",
      "Iteration 14, loss = 0.58218369\n",
      "Validation score: 0.684932\n",
      "Iteration 15, loss = 0.53773005\n",
      "Validation score: 0.636986\n",
      "Iteration 16, loss = 0.61287094\n",
      "Validation score: 0.678082\n",
      "Iteration 17, loss = 0.56808793\n",
      "Validation score: 0.657534\n",
      "Iteration 18, loss = 0.58542609\n",
      "Validation score: 0.732877\n",
      "Iteration 19, loss = 0.48167649\n",
      "Validation score: 0.780822\n",
      "Iteration 20, loss = 0.49936592\n",
      "Validation score: 0.739726\n",
      "Iteration 21, loss = 0.43172683\n",
      "Validation score: 0.787671\n",
      "Iteration 22, loss = 0.39683001\n",
      "Validation score: 0.753425\n",
      "Iteration 23, loss = 0.38825422\n",
      "Validation score: 0.773973\n",
      "Iteration 24, loss = 0.44254269\n",
      "Validation score: 0.821918\n",
      "Iteration 25, loss = 0.40051664\n",
      "Validation score: 0.821918\n",
      "Iteration 26, loss = 0.34485843\n",
      "Validation score: 0.828767\n",
      "Iteration 27, loss = 0.38530108\n",
      "Validation score: 0.506849\n",
      "Iteration 28, loss = 0.65809715\n",
      "Validation score: 0.821918\n",
      "Iteration 29, loss = 0.54199810\n",
      "Validation score: 0.835616\n",
      "Iteration 30, loss = 0.50840430\n",
      "Validation score: 0.794521\n",
      "Iteration 31, loss = 0.42158241\n",
      "Validation score: 0.726027\n",
      "Iteration 32, loss = 0.47100851\n",
      "Validation score: 0.760274\n",
      "Iteration 33, loss = 0.38084899\n",
      "Validation score: 0.794521\n",
      "Iteration 34, loss = 0.30446780\n",
      "Validation score: 0.821918\n",
      "Iteration 35, loss = 0.32046464\n",
      "Validation score: 0.698630\n",
      "Validation score did not improve more than tol=0.000010 for 5 consecutive epochs. Stopping.\n",
      "CPU times: total: 1.62 s\n",
      "Wall time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(60,50,40), \n",
    "    activation = 'relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001, # Strength of the L2 regularization term\n",
    "    batch_size='auto',\n",
    "    learning_rate = 'constant',\n",
    "    learning_rate_init = 0.001,\n",
    "    max_iter=200,\n",
    "    tol=0.00001, \n",
    "    early_stopping = True,\n",
    "    n_iter_no_change = 5,\n",
    "    verbose=True\n",
    "    \n",
    ")\n",
    "_ = model1.fit(X_train, y_train)\n",
    "\n",
    "# Currently (version 1.2.2), MLPClassifier supports only the Cross-Entropy loss function.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.35123363876668,\n",
       " 7.491125594164363,\n",
       " 8.826111731490588,\n",
       " 6.14701907217089,\n",
       " 5.336490166374211,\n",
       " 4.263663121678422,\n",
       " 3.287859165245858,\n",
       " 1.8174714002752275,\n",
       " 1.6340512852206226,\n",
       " 0.9955073943485522,\n",
       " 0.8432444784895147,\n",
       " 0.6897420579156748,\n",
       " 0.6297317991003879,\n",
       " 0.5821836913139338,\n",
       " 0.5377300490520339,\n",
       " 0.6128709393975389,\n",
       " 0.5680879275254829,\n",
       " 0.5854260899293794,\n",
       " 0.4816764918334295,\n",
       " 0.49936591975199024,\n",
       " 0.4317268279150596,\n",
       " 0.39683001214698777,\n",
       " 0.38825421661873943,\n",
       " 0.4425426923755952,\n",
       " 0.40051663626810424,\n",
       " 0.34485843375019304,\n",
       " 0.38530107965388355,\n",
       " 0.6580971492866534,\n",
       " 0.5419980968100468,\n",
       " 0.5084042991217271,\n",
       " 0.4215824143713198,\n",
       " 0.47100850793731047,\n",
       " 0.3808489850724948,\n",
       " 0.30446779651675515,\n",
       " 0.32046464165393795]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 12.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.828     0.977     0.896       301\n",
      "           1      0.973     0.805     0.881       313\n",
      "\n",
      "    accuracy                          0.889       614\n",
      "   macro avg      0.901     0.891     0.889       614\n",
      "weighted avg      0.902     0.889     0.889       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7.2 MLP Classifier with RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.62 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [ (64,), (128,),(128,64), (64,128), (64,128,196), (196,128,64)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .0001, .0005, .001, .005],\n",
    "    'batch_size': [25, 50, 100],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.0005, 0.001, 0.005, 0.01],\n",
    "    'max_iter': [5000],\n",
    "    'tol': [0.000005, 0.00001, 0.00005],\n",
    "    'early_stopping':[True],\n",
    "    'n_iter_no_change':[5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = MLPClassifier(), # a blank slate... RandomizedSearchCV will send parameters.\n",
    "    param_distributions=param_distributions, \n",
    "    cv=3, \n",
    "    n_iter=300,\n",
    "    scoring='accuracy', # note that we could also choose any other scoring metric that is appropriate for a multi-class problem - such as f1_macro, f1_micro, f1_weighted, etc.\n",
    "    verbose=1, \n",
    "    n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "_ = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 1e-05, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (64,), 'early_stopping': True, 'batch_size': 25, 'alpha': 0.0001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "model2 = random_search.best_estimator_\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.911     0.917     0.914       301\n",
      "           1      0.920     0.914     0.917       313\n",
      "\n",
      "    accuracy                          0.915       614\n",
      "   macro avg      0.915     0.915     0.915       614\n",
      "weighted avg      0.915     0.915     0.915       614\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 19.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.1 Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 32.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 64,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 64,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['sparse_categorical_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8.2 Keras with RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 140.3801\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 121.7119\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 91.2213\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 83.2160\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.6035\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.1205\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.9521\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.2779\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 28.7153\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 22.5587\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 202.1717\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 143.4026\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 126.8602\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 103.5529\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.4876\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.0928\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.5542\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.7600\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.5683\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 27.3896\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 181.8761\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 152.2196\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 126.2209\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106.0106\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 80.8426\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 71.4944\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 51.0558\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.5479\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.6005\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 29.2521\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 294.9793\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2935\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2867\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2800\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2733\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.2599\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2533\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2467\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2401\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 284.9048\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2939\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2871\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2804\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2737\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2670\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.2603\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2537\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2471\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2405\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 292.4753\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.2939\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.2871\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2804\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2737\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2670\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2603\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2537\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2471\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2405\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 1s 3ms/step - loss: 280.4520\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 8.8366\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 4.4349\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 3.9283\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 2.1792\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.0697\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8857\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4747\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3714\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4366\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 152.9936\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 5.2028\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.9300\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.5776\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.3676\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8264\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7031\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4939\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4469\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 38.0575\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4424\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7766\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9525\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3929\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4066\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4353\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4581\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5487\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4557\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 260.0260\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66.5704\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 38.7866\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.2856\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 35.1051\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 34.7083\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32.6195\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.0614\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.3569\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.4402\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 52.3921\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 49.4501\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 44.4512\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 44.4179\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.5361\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 38.3812\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 38.5062\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.1020\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32.7774\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 28.3720\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 136.9704\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 52.3040\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 45.6219\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 41.1638\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.4573\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.1036\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.7297\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.5582\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 35.0762\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32.3584\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 3ms/step - loss: 95.4704\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 47.7311\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.5469\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22.9949\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.6117\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.0270\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 6.1866\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.4751\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9317\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7455\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 117.1432\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 40.6896\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24.7909\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3762\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 11.3926\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 7.2171\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 4.1948\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.6447\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2378\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6543\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 101.1341\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.1082\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.6560\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 9.4177\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.4625\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.4830\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8724\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5981\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9212\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8615\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 107.8575\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.5119\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3704\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 26.8104\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 22.7471\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 17.1952\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13.2629\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4940\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.2787\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5886\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 134.5704\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.3536\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.7167\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.9594\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.0344\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 24.1586\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.1470\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.8448\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.3089\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.1678\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 231.9175\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 49.3655\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.0723\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3725\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 29.5427\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 25.3535\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.4832\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13.3866\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.0061\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.1170\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 109.5128\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 22.2583\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5740\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.0838\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0542\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8660\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7769\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7589\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7253\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7398\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 87.7774\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.4759\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 21.6711\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 9.6007\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8153\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6121\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8886\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4837\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1256\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8841\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 196.1913\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.6395\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 26.4804\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 14.0295\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2500\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7018\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7399\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9869\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9529\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8199\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 141.4945\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 88.3478\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58.9802\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.4189\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28.4954\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26.3322\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.3637\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 9.9595\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 7.4758\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 5.6829\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 164.7630\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 118.6322\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 80.4664\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56.3543\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33.6847\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23.3875\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.4240\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.9916\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 8.1040\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 5.8098\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 151.5980\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 106.8422\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 90.8349\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59.7283\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46.8749\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28.2932\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21.5303\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 14.5993\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 9.4245\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 6.8766\n",
      "9/9 [==============================] - 0s 814us/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 173.4396\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 148.9999\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 109.9739\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 94.6956\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 66.5000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.3114\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3857\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.7525\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0077\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 28.2005\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 142.6309\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 104.5814\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 87.7321\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 72.0273\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.2169\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 46.6967\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.4713\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30.4025\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 21.8941\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.7235\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 160.5271\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 109.0530\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 94.6782\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.5437\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.1919\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.9478\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.4663\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.4513\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.4024\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 21.5599\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 98.4837\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 81.1853\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51.4847\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.1014\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22.5258\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 18.1919\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 11.7073\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.6836\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 5.5706\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 4.3477\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 219.6396\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 149.8768\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 112.5073\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 85.7863\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55.5845\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.4235\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29.3404\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19.6320\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 14.8746\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 9.2117\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 158.4042\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59.4056\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46.9067\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28.8608\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24.7224\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 15.4057\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 10.6643\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 7.0389\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 4.9196\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.9874\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28.3022\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.3397\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 9.2980\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 15.9969\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.7769\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 12.8837\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2126\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5778\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4881\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4425\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 45.9995\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 39.8764\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27.5115\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.2754\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 6.6717\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8974\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.0987\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8464\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3191\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7710\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 132.3210\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 67.5331\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 15.4704\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.2824\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5476\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8152\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6738\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3560\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4161\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 354.6930\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2935\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2867\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2800\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2733\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2599\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2533\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2467\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2401\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 2ms/step - loss: 194.4729\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2935\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2867\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2800\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2733\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2599\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2533\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2467\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2401\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 390.3779\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2935\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2867\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2800\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2733\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2599\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.2533\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2466\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2401\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 11489.0029\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0396\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8818\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.7431\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6224\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5182\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4284\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3514\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2853\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2286\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 60224.4688\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0397\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8818\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.7432\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6224\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5182\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4284\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3514\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2853\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2285\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 4188.9277\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0411\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.8832\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.7443\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6235\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5190\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4292\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3521\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2859\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2290\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.2351\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 17.2814\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.0483\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.2893\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6611\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0820\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8467\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6072\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4331\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3911\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 186.2631\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31.4664\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.2770\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.4934\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.6689\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3994\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5422\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3583\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3663\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3698\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 225.1062\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.8703\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 25.9358\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.3204\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8499\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1472\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1660\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.1353\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.5376\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2528\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 206490.8125\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2133\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.1496\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0883\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0293\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9727\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9185\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.8171\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7698\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 322935.7812\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2133\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.1496\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.0883\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0293\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9728\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9185\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.8171\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7697\n",
      "9/9 [==============================] - 0s 999us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 325851.1562\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2133\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.1496\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0293\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.9727\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9185\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8171\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7697\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 548.2345\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2976\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2856\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2817\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2738\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2698\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 469.7698\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2976\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2857\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2817\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2738\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2699\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 704.9843\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2978\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2939\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2899\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2859\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2819\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2780\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2740\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2701\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2662\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 451.5701\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 413.8341\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 376.0516\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 338.1878\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 303.9554\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 289.6846\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 273.6002\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 257.4547\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 242.3713\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 227.6143\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 256, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\pipeline.py\", line 686, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1442, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels.astype(\"int64\", copy=False)]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 2\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 301.7791\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 254.4754\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 207.3729\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 160.2429\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 113.0946\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.2835\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.6595\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.9990\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 20.1314\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.9409\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 209.8043\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 173.7078\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 137.6682\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 101.6778\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.7869\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.6011\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.6266\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 17.0134\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6046\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.3698\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 344.2902\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 329.0464\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 308.0675\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 287.4030\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 261.6426\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 248.0886\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 228.7066\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 207.8226\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 192.8739\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 168.4180\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 922.1813\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 891.5845\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 857.6882\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 832.7116\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 800.3632\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 769.2242\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 733.8578\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 699.0224\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 669.2938\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 643.7278\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 256, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\pipeline.py\", line 686, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1442, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels.astype(\"int64\", copy=False)]\n",
      "IndexError: index 3 is out of bounds for axis 0 with size 2\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 715.1686\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 693.1362\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 675.8328\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 658.4986\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 637.1302\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 619.6465\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 605.3041\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 584.7579\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 562.8077\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 546.8483\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 73.8131\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 28.2924\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.2675\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.7319\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.6650\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 9.9157\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13.4085\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9.9461\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.1048\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.8865\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 81.5462\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 31.1118\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.8864\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 20.8629\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 20.8963\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18.9819\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11.3780\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.3558\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0817\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8511\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 121.4695\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 17.2384\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.1686\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13.0489\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.6081\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.8186\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3169\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7738\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1388\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5558\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 65.1421\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 37.0129\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.8277\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3243\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5599\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1849\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0757\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8517\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8706\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7716\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 3ms/step - loss: 83.2812\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 39.5395\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.4469\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.6359\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9875\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0225\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9271\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8079\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7349\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7379\n",
      "9/9 [==============================] - 0s 999us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 80.5543\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.7580\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.5680\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8805\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2300\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9743\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7840\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8141\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7507\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7491\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 95.8275\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 9.6108\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.7829\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.6895\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.2571\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.8767\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.1997\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8522\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1156\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4093\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 97.8021\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.4059\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.5493\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5703\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4110\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2058\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.2055\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.1507\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1071\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8055\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 397.6581\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 75.8725\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.9094\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.5511\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.1497\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15.0415\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.7780\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12.6040\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11.9048\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.1370\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 479.6006\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 324.3546\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 174.7377\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 85.5339\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 28.2070\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8033\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5470\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5260\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4824\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4486\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 441.5613\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 251.6471\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 72.0833\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5366\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6668\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6386\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5523\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4874\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4508\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4304\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 254.0820\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 135.7449\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 64.7643\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 6.6298\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9073\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8172\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7794\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7057\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6651\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6694\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 302.9730\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 48.5899\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2333\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.0223\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0099\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8614\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8594\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8910\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.7684\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7560\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 299.4667\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 93.9860\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 6.0567\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0461\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.9594\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8064\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.6907\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4968\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4410\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.5030\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 108.9452\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 5.5132\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.0670\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.0933\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9903\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9203\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9785\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8176\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8544\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.7667\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3731.0693\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2525\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2139\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1762\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1392\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1031\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0677\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0332\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9996\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9668\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 274305.8125\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2528\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2142\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1764\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1394\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1033\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0679\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0334\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9998\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9669\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 251864.6719\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2527\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2141\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1764\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1394\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1033\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0679\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0335\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9998\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9669\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 803.4884\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2975\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2856\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2816\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2737\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2698\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 846.5510\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.2975\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2856\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2816\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2737\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2698\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 969.8036\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2975\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2856\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2816\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2737\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2698\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 110.9582\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 30.0851\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 12.5689\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 5.2461\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8149\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7318\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6473\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5248\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5288\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5302\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 61.9930\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 18.1085\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 7.1596\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1592\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.1999\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7657\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5879\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6349\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5288\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5308\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 74.2524\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 26.0861\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 7.9310\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.8004\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.1100\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7322\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6674\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6295\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6084\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5857\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 524.1102\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 254.5332\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 122.1289\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.6689\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.3948\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.2303\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.9381\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.7371\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.7416\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.0741\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 3ms/step - loss: 140.5067\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 53.6188\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 46.3941\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.9264\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.0100\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.1821\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.6815\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 39.7517\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5445\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 34.4642\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 98.8445\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 37.3567\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 30.7087\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 27.1723\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 28.2849\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 29.1152\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24.7057\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 26.0604\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 24.4921\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.6763\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3057395.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4779\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1847\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0480\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9701\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9188\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8814\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8528\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8304\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8125\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4627897.5000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5700\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1981\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0284\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9355\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8813\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8447\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8194\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8017\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7877\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42277056.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3229\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0693\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9525\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8844\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8506\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8190\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8021\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7830\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7725\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 18.4430\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6352\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.1622\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5109\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4559\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4398\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3666\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5868\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3702\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4563\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 45.6127\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.5750\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6626\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3561\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5204\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4539\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6655\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4978\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2901\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3790\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 13.9291\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9025\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8761\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8632\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3813\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4896\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4812\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4012\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5152\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4236\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 467.7874\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 184.7261\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 80.5758\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 21.9330\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 9.4270\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2128\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.1163\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4871\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9536\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8169\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 132.5886\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 23.5113\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 11.2949\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.9181\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0409\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0711\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.0223\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.5655\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2984\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1662\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 441.2937\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 163.4759\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.6599\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.1481\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0405\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.8849\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4609\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0019\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7827\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7024\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 118.4842\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 37.0620\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 11.2638\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 3.8627\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0590\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7374\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6127\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5191\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5285\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5326\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 87.1568\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 25.7705\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 8.2473\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.7921\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.1661\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6347\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5763\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4859\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5494\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 108.9290\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 33.7746\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 14.0797\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 4.2512\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8840\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7046\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5436\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5345\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4590\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4876\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 222.8049\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 134.6355\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 68.6409\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 9.2116\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9245\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8113\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7829\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7444\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7172\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6906\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 746.3505\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 559.8595\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 374.5752\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 230.6800\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 164.5928\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 100.3910\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 34.9096\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.9889\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.6799\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 2.4854\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 522.8080\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 346.6774\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 258.0136\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 184.7451\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 109.4888\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 33.0155\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5540\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3282\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2235\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.1813\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5997694.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9943\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8377\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7019\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5876\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4817\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4081\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3325\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2716\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2051\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5734.8594\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3063\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0755\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9597\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8994\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8634\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8288\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8117\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8003\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7881\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5382611.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3653\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1018\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0219\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9435\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9019\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8631\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8544\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8182\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8137\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 88.4636\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 36.3074\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23.8141\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 19.4507\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.4137\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.2477\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.3734\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3506\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.4696\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9983\n",
      "9/9 [==============================] - 0s 999us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 88.0283\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28.0561\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 17.4468\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 11.4997\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.9599\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.0293\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.3479\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5634\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8158\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7362\n",
      "9/9 [==============================] - 0s 999us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 188.3462\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 50.9955\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29.5848\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20.4023\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.0874\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 11.1573\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.6058\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.3083\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.5003\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7237\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47.2458\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21.0091\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 16.5337\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.4960\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7013\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0464\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.5066\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0963\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7307\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4317\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 2ms/step - loss: 45.5218\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.0429\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 5.0980\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8809\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3523\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.4165\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.9748\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.8095\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.8395\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6262\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48.5491\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6485\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 6.5025\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 3.2299\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.1094\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 6.7038\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4120\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2280\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 4.5920\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.3324\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 676.7538\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.7148\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2940\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2900\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2820\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2781\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2741\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2702\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2663\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 890.6487\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2983\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2944\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2904\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.2864\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2824\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2785\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2745\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2706\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2667\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 665.8472\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2975\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2856\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2816\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2737\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2698\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 605.9936\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 566.3751\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 529.6500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 481.1276\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 451.2063\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 403.5366\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 366.0252\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 328.8372\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 282.7621\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 248.7770\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 256, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\pipeline.py\", line 686, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1442, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels.astype(\"int64\", copy=False)]\n",
      "IndexError: index 3 is out of bounds for axis 0 with size 2\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 470.0782\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 438.1730\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 400.6724\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 373.6652\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 339.1690\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 309.4514\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 284.7029\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 250.5402\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 223.9139\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 201.7514\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 256, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\pipeline.py\", line 686, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1442, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels.astype(\"int64\", copy=False)]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 2\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 834.9404\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 793.4894\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 749.0915\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 688.1240\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 656.0274\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 610.0636\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 553.9738\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 507.4230\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 458.1970\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 415.6485\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 256, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\pipeline.py\", line 686, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1442, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels.astype(\"int64\", copy=False)]\n",
      "IndexError: index 3 is out of bounds for axis 0 with size 2\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 16830734.0000\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1572\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9480\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8630\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8178\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7916\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7730\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7608\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7524\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7456\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40090896.0000\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2139\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0074\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9091\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8542\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8203\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7973\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7807\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7688\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7595\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2900812.0000\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1532\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9385\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8537\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8101\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7845\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7675\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7559\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7472\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7404\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108.7564\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26.8198\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 22.3619\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.5741\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3292\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.5567\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7468\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7593\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1841\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.5003\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 52.1973\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 18.3815\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9780\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.1493\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3720\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6977\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8320\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3533\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5153\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1451\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 126.2635\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.9282\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 22.0810\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.1211\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12.2681\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.7963\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.5544\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.8862\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6561\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.0116\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 35.9191\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2745\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 2.2552\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2362\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2174\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1987\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1803\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1620\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1440\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1261\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 201.1169\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2744\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2552\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2361\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2173\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1986\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1802\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1620\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1439\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1261\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 165.6543\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2748\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2555\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2365\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.2177\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1990\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1806\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1623\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1443\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.1264\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 11817.6914\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0396\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8818\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.7431\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6224\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5182\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4284\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3514\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2853\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2286\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 6706.9482\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0431\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.8848\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.7458\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6247\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5201\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4301\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3529\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2866\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2296\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 51583.9375\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2.0395\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.8817\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.7431\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.6224\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.5181\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.4284\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.3514\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2853\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.2285\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 100338.5312\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2136\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.1498\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0885\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.0295\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9730\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9187\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8668\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8173\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7699\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1162.4143\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2133\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.1495\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0293\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9727\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9185\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8666\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8170\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7697\n",
      "9/9 [==============================] - 0s 925us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 181122.1094\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2133\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.1496\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.0293\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9727\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.9185\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8171\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.7697\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 154.1211\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 98.2767\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 67.6629\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42.7109\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.6335\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22.3409\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 17.2791\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.5537\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 7.3256\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 4.9198\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 170.6063\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 114.6836\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 78.3742\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55.3263\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9343\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23.0524\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.0100\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.9931\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 8.5373\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.3164\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 141.8113\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 108.3291\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 85.3913\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52.5918\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.4329\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28.4069\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 20.7080\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 12.7531\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 10.4989\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 7.0758\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 345.3174\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2943\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2876\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2808\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 2.2741\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 976us/step - loss: 2.2674\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2608\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2541\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2475\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2409\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 591.0699\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2935\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2867\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2800\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2733\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2599\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2533\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2467\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2401\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 170.3723\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2934\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2866\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2799\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2732\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2665\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2598\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2532\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.2466\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.2400\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 67.5111\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.0789\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.2043\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 26.1789\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.1961\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.2933\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.9465\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.5033\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.4080\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.7481\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 181.1982\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 63.6937\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 37.7932\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 29.8886\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 23.1187\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.6363\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.5891\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.6577\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.5275\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0545\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 169.1035\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.8219\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 58.7405\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.1621\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.1120\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 30.7400\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.8130\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.3374\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.8530\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.2564\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 182.8668\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 132.6670\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 84.6377\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 66.2844\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 52.2902\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.3241\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3491\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 41.9789\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 41.1132\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.9495\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 335.8108\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 269.3622\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 222.1665\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 170.5842\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 126.9973\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 90.5723\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.9280\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 66.4741\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.6979\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 54.1199\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 390.4171\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 321.6170\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 264.3234\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 210.1558\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 162.2784\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 130.0881\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 91.9736\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.5357\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 66.8427\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 59.9040\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 1s 3ms/step - loss: 238.8976\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 76.2341\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 59.8821\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 56.8782\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 50.7162\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 47.7966\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 51.5500\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 41.7437\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 45.0044\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 38.5650\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 1s 3ms/step - loss: 58.9297\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 47.1969\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 44.6978\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 42.3369\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 40.5122\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 38.1174\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 34.3385\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 32.5944\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 32.4441\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 28.6615\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 1s 3ms/step - loss: 293.6310\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 97.7674\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 62.1991\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 58.2841\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 56.8640\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 48.4200\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 53.9572\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 48.3764\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 44.5405\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 45.4820\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 498.4845\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2976\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.2897\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2857\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2817\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2778\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2738\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2699\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2660\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 391.2029\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2976\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2936\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2896\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2856\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2817\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2777\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2738\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2698\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2659\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 274.3800\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8756\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8608\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8525\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8533\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8755\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8567\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8729\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8607\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8455\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 25765.5898\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1.0056\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8567\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7992\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7742\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7558\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7444\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7360\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.7281\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7300\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 2507.1802\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9100\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8088\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7686\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7479\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7360\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7280\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7228\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7185\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7159\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 1007905.0625\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9260\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8362\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.8087\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7802\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7520\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7385\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7473\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.7329\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 313495.6562\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2528\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2142\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1764\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1394\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1033\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0679\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0334\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9998\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9669\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 2ms/step - loss: 128894.8047\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2536\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2149\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1772\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1402\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1040\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0687\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0341\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0005\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9676\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5882.2568\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2528\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2141\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1764\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1394\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1033\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0679\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0335\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9998\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9669\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.50068446 0.49931554 0.74870642 0.59240246 0.69855474 0.79594843\n",
      " 0.57460643 0.49931554 0.50068446 0.5        0.71365095 0.49931554\n",
      " 0.49931554 0.69772944 0.49931554 0.49931554        nan        nan\n",
      " 0.71850838 0.54595195 0.68617385 0.76705171 0.54866586 0.49931554\n",
      " 0.49931554 0.68959898 0.51440188 0.50068446 0.734282   0.46723874\n",
      " 0.68206708 0.5549063  0.50068446 0.81571476 0.69166082 0.49931413\n",
      "        nan 0.5        0.69866882 0.49931554 0.49931554 0.49931554\n",
      " 0.51368925 0.5        0.85547134 0.50068446 0.53909324 0.49931554\n",
      " 0.5        0.5       ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 71.5150\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 42.1546\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 30.3899\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.2704\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 11.6875\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 7.1034\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.5780\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.5456\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0592\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8238\n",
      "CPU times: total: 17min 38s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='accuracy',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=50, \n",
    "    cv=3)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)\n",
    "\n",
    "# You can create 'call back' functions. These are functions that will be called at the \n",
    "# end of each epoch. There are a number of builtin functions created for this purpose, \n",
    "# one of which is EarlyStopping -- that, based on the parameters you give, will stop\n",
    "# the training process. This is useful when the algorithm is not making any significant\n",
    "# gains through further training. \n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "#callback = [earlystop]\n",
    "#_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.01,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (100,),\n",
       " 'model__dropout': 0.1,\n",
       " 'loss': 'sparse_categorical_crossentropy',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 100}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.681     1.000     0.810       301\n",
      "           1      1.000     0.550     0.709       313\n",
      "\n",
      "    accuracy                          0.770       614\n",
      "   macro avg      0.840     0.775     0.760       614\n",
      "weighted avg      0.844     0.770     0.759       614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the Decision Trees have the best recall score of all the models that we have tried. We achieved a sore of 95.52 using decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Next best metric we have is SupportVectorMachine using RBF Kernel. But let us go with Decision Trees as we have better score there in addition to the fact that Decision Trees deal with colinear data in a better way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if we look at the recall scores of the NeuralNets, they are 86 with RandomSearchCv and 67 with GridSearch. We have The Decision Trees performing better than thge neuralnets in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Final goal is to achieve the best recall score so that we can reduce False Negatives as much as we can. Theoretically, we can achieve a recall score upto 1 and in reality, we achieved it upto 0.955. So, we have dealt with the issue in the best possible way we can and reduced the occurances of false negatives."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPs and Keras Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, We have Neural Networks using MLPClassifier and Keras and the outputs are here to see.\n",
    "\n",
    "* MLP Classifier has a recall value of 80.5\n",
    "* MLP Classifier with RandomisedSearchCV has a recall value of 91.4\n",
    "* Keras achieved a recall value of 55\n",
    "\n",
    "The reason for Decision trees out-performing these ML Models is because DecisionTrees explicitly fit the parameters into the model to manage the flow of inputs where-as NeuralNets with MLPs and Keras fit parameters to transform the input and indirectly direct the activations of following neurons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
